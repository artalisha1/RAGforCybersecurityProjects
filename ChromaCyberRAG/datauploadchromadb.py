# -*- coding: utf-8 -*-
"""DataUploadChromaDB

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1b_wDF3C8VnqUpOrAC9IiAEaMYgCM1KP0

#Uploading Data to ChromaDB

## Objective
Uploading MITRE ATT&CK and CISA Advisories data into Chroma, a high-performance vector database, using Python. Aligns with the MITRE embed project and supports Retrieval-Augmented Generation (RAG) in cybersecurity.

##Step 1: Set Up the Enviornment
"""

!pip install chromadb pandas transformers

"""##Step 2: Load the MITRE Att&CK Data"""

import pandas as pd

# Load the MITRE ATT&CK datasets
mitre_data = pd.read_csv('/content/mitreembed_master_Chroma.csv', sep='\t', on_bad_lines='skip')
print("MITRE Data Sample:\n", mitre_data.head())

cisa_data = pd.read_csv('CISA_combo_features_new.csv')
print("CISA Data Sample:\n", cisa_data.head())

"""## Step 3: Initialize the Sentence Transformer"""

!pip install -U langchain-community

#sentence embedding model
from sentence_transformers import SentenceTransformer
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import Chroma

# This line downloads the 'all-MiniLM-L12-v2' Sentence Transformer model
original_model = SentenceTransformer('all-MiniLM-L12-v2')

# reload model using langchain wrapper
# This line saves the downloaded model to the current directory
original_model.save('./')

# Define the path where the embedding model is saved
embedding_model_path = './'
# Initialize HuggingFaceEmbeddings with the local model path
# This wraps the Sentence Transformer model for use with LangChain
embedding_model = HuggingFaceEmbeddings(model_name=embedding_model_path)

# Define example sentences to be embedded
sentences = ["This is an example sentence", "Each sentence is converted"]

# Re-initialize the Sentence Transformer model
model = SentenceTransformer('sentence-transformers/all-MiniLM-L12-v2')
# Encode the example sentences into embeddings
embeddings = model.encode(sentences)

# Re-initialize HuggingFaceEmbeddings again
embedding_model = HuggingFaceEmbeddings(model_name=embedding_model_path)

# Print the generated embeddings
print(embeddings)

""" ## Step 4: Setup ChromaDB"""

# Import necessary libraries
from langchain.vectorstores import Chroma  # For interacting with the Chroma vector database
import chromadb  # The ChromaDB client library
from sentence_transformers import SentenceTransformer # For creating sentence embeddings

from langchain.document_loaders import DataFrameLoader # To load data from pandas DataFrames into a document format
from langchain.embeddings import HuggingFaceEmbeddings # To use HuggingFace models for creating embeddings
import re # Regular expression operations

import pandas as pd # For data manipulation and analysis, especially with DataFrames

# define logic for embeddings storage
# Define the path for storing ChromaDB data (in the current directory)
chromadb_path = './'
# Initialize the ChromaDB client
chroma_client = chromadb.Client()
# Print the version of the ChromaDB client
print(chroma_client.get_version())

# Handle missing values in the 'Body' column
mitre_data['Body'] = mitre_data['Body'].fillna('')

# assemble product documents in required format (id, text)
# Create a DataFrameLoader instance, specifying that the 'Body' column contains the document content
loader = DataFrameLoader(
    mitre_data,
    page_content_column='Body'
    )

# Load the data from the mitre_data DataFrame into a list of Document objects
documents = loader.load()

"""## Step 5: Define Logic for embeddings storage"""

chromadb_path = './'

# Create a Chroma vector store from the documents and embeddings
vectordb = Chroma.from_documents(
  documents=documents, # The list of documents to embed and store
  embedding=embedding_model, # The embedding model to use
  persist_directory=chromadb_path, # The directory where the ChromaDB data will be stored
  collection_name = 'CISA_MITRE' # Optional: specify a name for the collection
  )

# persist vector db to storage
vectordb.persist()

"""## Step 6: Check the number of collections in the vectorDB"""

#count documents
vectordb._collection.count()

"""## Step 7: Query ChromaDB for MITRE-related"""

query_text = "remote desktop attack"
vectordb.similarity_search_with_score(query_text)
#Response: Rows that closely aligns with remote desktop attack, meta data of row
# and file path which includes the technique

"""## Step 8: Inspect a record"""

#examine a vector db record
#shows a random record where metadata matches the query text
rec = vectordb._collection.peek(1)
# Print the metadata of the record
print('Metadata:  ', rec['metadatas'])
# Print the document content of the record
print('Documents:  ', rec['documents'])
# Print the IDs of the records
print('ids:        ', rec['ids'])
# Print the embeddings of the records
print('embeddings: ', rec['embeddings'])

"""## Step 9: Real-World Use Cases
By integrating ChromaDB with MITRE ATT&CK data, cybersecurity analysts can:

1. Rapidly map alerts to known techniques.
2. Cross-reference threat intelligence feeds.

## Conclusion
By leveraging ChromaDB and RAG frameworks, we can transform static cybersecurity data into dynamic, actionable insights.
"""